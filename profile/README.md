# ğŸ’Š Multi-Omics-Based Drug Sensitivity Estimation  
*6th YAICON â€” Spring 2025 Â· **Second Prize***

---

## ğŸ“Œ Overview
Accurately predicting how a cancer cell line responds to a drug (IC-50) remains an open challenge: the outcome depends not only on the drugâ€™s chemistry but also on the cellâ€™s intricate molecular profile.  
We present an end-to-end deep-learning pipeline that **fuses three omics layers (GEP, MUT, CNV)** with advanced **drug-embedding models (ChemBERTa & graph-based GNN)** and a **bi-directional cross-attention mechanism**. Our approach improves upon the 2025 benchmark paper  
[*â€œAnticancer drug response prediction integrating multi-omics pathway-based difference features and multiple deep-learning techniques.â€*](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012905)

<p align="center">
  <img src="../assets/input.png" width="49%" />
  <img src="../assets/output.png" width="49%" />
</p>

---

## ğŸŒ± Why we built this
| Baseline limitation | Our upgrade |
| ------------------- | ----------- |
| **Drug representation lacks structural cues** (only SMILES RNN) | **Two interchangeable drug encoders**<br>â€¢ *ChemBERTa* â€” language-style SMILES embedding<br>â€¢ *BGD* â€” graph transformer on molecular graphs |
| **Shallow â€œcontext attentionâ€** canâ€™t model complex drug-omics interplay | **Deep, bi-directional cross-attention** (drug â†” each omics) giving **6 interaction maps** |

---

## ğŸ”¬ Data
| Source | Entities | Notes |
| ------ | -------- | ----- |
| **CCLE** | 688 cell lines | GEP (logâ‚‚ TPM + 1), MUT (0/1/2), CNV (logâ‚‚ discrete) |
| **GDSC2** | 233 drugs | Matched IC-50 ground-truth |
| **MSigDB â€“ 619 KEGG pathways** | â€“ | Used to derive pathway-difference statistics (Mann-Whitney U / Ï‡Â²-G) |

---

## ğŸ›  Methodology
1. **Omics pathway features**  
   For every cell line Ã— pathway, compute statistical separation between â€œin-pathwayâ€ and â€œout-pathwayâ€ genes â†’ 3 feature matrices of size 1 Ã— 619 (GEP, MUT, CNV).

2. **Drug embeddings**  
   *Choose one encoder at training time*  
   | Encoder | Key idea | Output shape |
   | ------- | -------- | ------------ |
   | **ChemBERTa** | Tokenise SMILES, pad to 256, take final hidden CLS | 1 Ã— 384 |
   | **BGD** | Graph transformer over atoms/bonds + DeepChem node feats | 1 Ã— 256 |

3. **Cross-attention block**  
   â€¢ Drug (Q) â†” Omics (K,V) for each omics type, **two directions** (drugâ†’omics, omicsâ†’drug) â†’ 6 attention layers in total.  
   â€¢ Concatenate pooled outputs â†’ stacked MLP â†’ IC-50 regression.

<p align="center">
  <img width="721" alt="Image" src="https://github.com/user-attachments/assets/41ab2228-32ab-4d2f-b0c4-82d408cc3f87" />
</p>

*Implementation diagram above: original (top) vs. modified cross-attention (bottom).*

---

## ğŸ“‚ Code & Repos

| Repository | Description |
| ---------- | ----------- |
| **[Drug-Sensitivity-Prediction-Pipeline](https://github.com/Omics-based-Drug-sensitivity-Estimation/Drug-Sensitivity-Prediction-Pipeline)** | Main training pipeline, model zoo, experiment scripts |
| **[DGL-Life-sci](https://github.com/Omics-based-Drug-sensitivity-Estimation/DGL-Life-sci)** | Custom extensions for graph-based drug encoders |

<details>
<summary>Model zoo snapshots</summary>

#### ChemBERTa Drug Embedding
<p align="center">
  <img width="333" alt="ChemBERTa" src="https://github.com/user-attachments/assets/9166787e-d33f-40ba-bce8-c465a705064e" />
</p>

#### Graph-Transformer Drug Embedding
<p align="center">
  <img width="305" alt="Graph" src="https://github.com/user-attachments/assets/f474ddbb-45e1-4ad6-bc99-8ab0bfc1fc74" />
</p>

</details>

---

## ğŸ“Š Results

<p align="center">
  <img src="https://github.com/user-attachments/assets/62b4dbd0-f510-4b20-95e9-4789627cb7c5" width="425" alt="Figure 1">
  <br><em>Figure 1. Drug embedding comparison (Original vs. Modified attention)</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/5f28a37e-4e18-4b83-8b3f-da5945e02404" width="425" alt="Figure 2">
  <br><em>Figure 2. Cross-attention variant performance</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/a4b6bc42-3e90-4d4f-80c2-3668d2330e41" width="700" alt="Figure 3">
  <br><em>Figure 3. Pearson r on cell-blinded split (scatter)</em>
</p>

Key takeaway : **+Improvement over the baseline when switching to ChemBERTa/BGD-Model + cross-attention. Full metrics in `/results/`.

---

## ğŸ”— Reference
* **PASO** â€“ <https://github.com/queryang/PASO>

---

## ğŸ‘¥ Team

| Name | Role | GitHub |
| ---- | ---- | ------ |
| **Yoonjin Cho** | Team lead Â· Proposal Â· Multi-omics & ChemBERT modeling Â· Server ops Â· Experiments Â· Visualisation | [@darejinn](https://github.com/darejinn) |
| **Gyungdeok Bae** | Presenter Â· Model dev lead Â· PASO & GNN design Â· Troubleshooting Â· Attention modules | [@bgduck33](https://github.com/bgduck33) |
| **Junseo Ha** | Graph-based drug rep (GIN, AttFP, MPNN) Â· PASO analysis Â· Experiments | [@Carolyn-Ha](https://github.com/Carolyn-Ha) |
| **Yoonju Cho** | Attention improvement Â· Baseline experiments | [@whdsbwn](https://github.com/whdsbwn) |
| **Daeseong Kim** | Initial idea Â· Dataset/AWS support Â· *in vitro* validation | [@lemonardo1](https://github.com/lemonardo1) |

---

